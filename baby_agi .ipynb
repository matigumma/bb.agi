{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "MZdjnXXMCKMU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZdjnXXMCKMU",
        "outputId": "9e6a0aa6-8deb-4984-d5d7-bffcd96299e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (0.0.139)\n",
            "Requirement already satisfied: pinecone-client in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (2.2.1)\n",
            "Requirement already satisfied: pyllamacpp in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (1.0.6)\n",
            "Requirement already satisfied: chromadb in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (0.3.21)\n",
            "Requirement already satisfied: SQLAlchemy<2,>=1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langchain) (1.4.47)\n",
            "Requirement already satisfied: gptcache>=0.1.7 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langchain) (0.1.10)\n",
            "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langchain) (0.5.7)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langchain) (3.8.4)\n",
            "Requirement already satisfied: numpy<2,>=1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langchain) (1.24.2)\n",
            "Requirement already satisfied: PyYAML>=5.4.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langchain) (6.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langchain) (2.28.2)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
            "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langchain) (1.2.4)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langchain) (4.0.2)\n",
            "Requirement already satisfied: pydantic<2,>=1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from langchain) (1.10.7)\n",
            "Requirement already satisfied: urllib3>=1.21.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from pinecone-client) (1.26.15)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from pinecone-client) (2.8.2)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from pinecone-client) (2.3.0)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from pinecone-client) (4.65.0)\n",
            "Requirement already satisfied: loguru>=0.5.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from pinecone-client) (0.7.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from pinecone-client) (4.5.0)\n",
            "Requirement already satisfied: sentencepiece in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from pyllamacpp) (0.1.98)\n",
            "Requirement already satisfied: streamlit-ace in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from pyllamacpp) (0.1.1)\n",
            "Requirement already satisfied: streamlit in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from pyllamacpp) (1.21.0)\n",
            "Requirement already satisfied: torch in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from pyllamacpp) (2.0.0)\n",
            "Requirement already satisfied: duckdb>=0.7.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from chromadb) (0.7.1)\n",
            "Requirement already satisfied: hnswlib>=0.7 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from chromadb) (0.7.0)\n",
            "Requirement already satisfied: clickhouse-connect>=0.5.7 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from chromadb) (0.5.20)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from chromadb) (2.5.0)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from chromadb) (0.21.1)\n",
            "Requirement already satisfied: pandas>=1.3 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from chromadb) (1.5.3)\n",
            "Requirement already satisfied: fastapi>=0.85.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from chromadb) (0.95.1)\n",
            "Requirement already satisfied: sentence-transformers>=2.2.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from chromadb) (2.2.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.2.0)\n",
            "Requirement already satisfied: lz4 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (4.3.2)\n",
            "Requirement already satisfied: pytz in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.3)\n",
            "Requirement already satisfied: zstandard in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (0.19.0)\n",
            "Requirement already satisfied: certifi in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2022.12.7)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
            "Requirement already satisfied: typing-inspect>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
            "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
            "Requirement already satisfied: starlette<0.27.0,>=0.26.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from fastapi>=0.85.1->chromadb) (0.26.1)\n",
            "Requirement already satisfied: cachetools in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from gptcache>=0.1.7->langchain) (5.3.0)\n",
            "Requirement already satisfied: openai in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from gptcache>=0.1.7->langchain) (0.27.4)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: six>=1.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
            "Requirement already satisfied: torchvision in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb) (0.15.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb) (0.13.4)\n",
            "Requirement already satisfied: scikit-learn in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.2.2)\n",
            "Requirement already satisfied: scipy in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb) (1.10.1)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb) (4.28.1)\n",
            "Requirement already satisfied: nltk in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from sentence-transformers>=2.2.2->chromadb) (3.8.1)\n",
            "Requirement already satisfied: filelock in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from torch->pyllamacpp) (3.11.0)\n",
            "Requirement already satisfied: networkx in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from torch->pyllamacpp) (3.1)\n",
            "Requirement already satisfied: sympy in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from torch->pyllamacpp) (1.11.1)\n",
            "Requirement already satisfied: jinja2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from torch->pyllamacpp) (3.1.2)\n",
            "Requirement already satisfied: click>=7.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
            "Requirement already satisfied: h11>=0.8 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
            "Requirement already satisfied: websockets>=10.4 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.1)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.5.0)\n",
            "Requirement already satisfied: validators>=0.2 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from streamlit->pyllamacpp) (0.20.0)\n",
            "Requirement already satisfied: toml in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from streamlit->pyllamacpp) (0.10.2)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from streamlit->pyllamacpp) (6.2)\n",
            "Requirement already satisfied: pympler>=0.9 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from streamlit->pyllamacpp) (1.0.1)\n",
            "Requirement already satisfied: gitpython!=3.1.19 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from streamlit->pyllamacpp) (3.1.31)\n",
            "Requirement already satisfied: tzlocal>=1.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from streamlit->pyllamacpp) (4.3)\n",
            "Requirement already satisfied: protobuf<4,>=3.12 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from streamlit->pyllamacpp) (3.20.3)\n",
            "Requirement already satisfied: pydeck>=0.1.dev5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from streamlit->pyllamacpp) (0.8.0)\n",
            "Requirement already satisfied: importlib-metadata>=1.4 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from streamlit->pyllamacpp) (6.3.0)\n",
            "Requirement already satisfied: pyarrow>=4.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from streamlit->pyllamacpp) (11.0.0)\n",
            "Requirement already satisfied: blinker>=1.0.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from streamlit->pyllamacpp) (1.6.2)\n",
            "Requirement already satisfied: packaging>=14.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from streamlit->pyllamacpp) (23.1)\n",
            "Requirement already satisfied: rich>=10.11.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from streamlit->pyllamacpp) (13.3.4)\n",
            "Requirement already satisfied: altair<5,>=3.2.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from streamlit->pyllamacpp) (4.2.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from streamlit->pyllamacpp) (9.5.0)\n",
            "Requirement already satisfied: toolz in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from altair<5,>=3.2.0->streamlit->pyllamacpp) (0.12.0)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from altair<5,>=3.2.0->streamlit->pyllamacpp) (4.17.3)\n",
            "Requirement already satisfied: entrypoints in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from altair<5,>=3.2.0->streamlit->pyllamacpp) (0.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from gitpython!=3.1.19->streamlit->pyllamacpp) (4.0.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from importlib-metadata>=1.4->streamlit->pyllamacpp) (3.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from jinja2->torch->pyllamacpp) (2.1.2)\n",
            "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from rich>=10.11.0->streamlit->pyllamacpp) (2.2.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from rich>=10.11.0->streamlit->pyllamacpp) (2.15.0)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from starlette<0.27.0,>=0.26.1->fastapi>=0.85.1->chromadb) (3.6.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (2023.3.23)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=2.2.2->chromadb) (0.13.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: pytz-deprecation-shim in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from tzlocal>=1.1->streamlit->pyllamacpp) (0.1.0.post0)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from validators>=0.2->streamlit->pyllamacpp) (5.1.1)\n",
            "Requirement already satisfied: joblib in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from nltk->sentence-transformers>=2.2.2->chromadb) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from scikit-learn->sentence-transformers>=2.2.2->chromadb) (3.1.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from sympy->torch->pyllamacpp) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette<0.27.0,>=0.26.1->fastapi>=0.85.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit->pyllamacpp) (5.0.0)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from jsonschema>=3.0->altair<5,>=3.2.0->streamlit->pyllamacpp) (0.19.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich>=10.11.0->streamlit->pyllamacpp) (0.1.2)\n",
            "Requirement already satisfied: tzdata in /opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages (from pytz-deprecation-shim->tzlocal>=1.1->streamlit->pyllamacpp) (2023.3)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "pip install langchain pinecone-client pyllamacpp chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "556af556",
      "metadata": {
        "id": "556af556"
      },
      "source": [
        "## Install and Import Required Modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c8a354b6",
      "metadata": {
        "id": "c8a354b6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"OPENAI_API_MODEL\"] = \"llama\"\n",
        "# os.environ[\"PINECONE_API_KEY\"] = \"a34bfd48-c239-41fc-a232-000531b93b0b\"\n",
        "# os.environ[\"PINECONE_ENVIRONMENT\"] = \"northamerica-northeast1-gcp\"\n",
        "os.environ[\"TABLE_NAME\"] = \"bb-table\"\n",
        "os.environ[\"INITIAL_TASK\"] = \"Make the list of tasks\"\n",
        "\n",
        "from collections import deque\n",
        "from typing import Dict, List, Optional, Any\n",
        "\n",
        "from langchain import LLMChain, PromptTemplate, PromptTemplate\n",
        "from langchain.embeddings import LlamaCppEmbeddings\n",
        "from langchain.llms import BaseLLM\n",
        "\n",
        "from langchain.llms import GPT4All\n",
        "from langchain.callbacks.base import CallbackManager\n",
        "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
        "from langchain.vectorstores.base import VectorStore\n",
        "from langchain.vectorstores import Chroma\n",
        "# from langchain.vectorstores import Pinecone\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain.chains.base import Chain\n",
        "from chromadb import errors as chromadb_errors\n",
        "\n",
        "# PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\", \"\")\n",
        "# PINECONE_ENVIRONMENT = os.getenv(\"PINECONE_ENVIRONMENT\", \"\")\n",
        "YOUR_TABLE_NAME = os.getenv(\"TABLE_NAME\", \"\")\n",
        "INITIAL_TASK = os.getenv(\"INITIAL_TASK\", os.getenv(\"FIRST_TASK\", \"\"))\n",
        "\n",
        "# import pinecone\n",
        "# pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_ENVIRONMENT)\n",
        "\n",
        "# pinecone.whoami()\n",
        "# Create Pinecone index\n",
        "table_name = YOUR_TABLE_NAME\n",
        "# dimension = 2048\n",
        "# dimension = 1536\n",
        "# metric = \"cosine\"\n",
        "# pod_type = \"p1\"\n",
        "# if table_name not in pinecone.list_indexes():\n",
        "    # pinecone.create_index(\n",
        "        # table_name, dimension=dimension, metric=metric, pod_type=pod_type\n",
        "    # )\n",
        "\n",
        "# Connect to the index\n",
        "# index = pinecone.Index(table_name)\n",
        "\n",
        "# index.describe_index_stats()\n",
        "\n",
        "# Task list\n",
        "# task_list = deque([])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "794045d4",
      "metadata": {
        "id": "794045d4"
      },
      "outputs": [],
      "source": [
        "# old test with vectorstore FAISS\n",
        "# ---------------------------------------------------------------- \n",
        "\n",
        "# from langchain.vectorstores import FAISS\n",
        "# from langchain.docstore import InMemoryDocstore"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "6e0305eb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "6e0305eb",
        "outputId": "e85abb70-a179-4217-bd9c-daa3f60a511e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "1it [00:00, 437.09it/s]\n",
            "llama_model_load: loading model from './gpt4all-lora-quantized-OSX-m1.bin' - please wait ...\n",
            "./gpt4all-lora-quantized-OSX-m1.bin: invalid model file (bad magic [got 0x6d74683c want 0x67676a74])\n",
            "\tyou most likely need to regenerate your ggml files\n",
            "\tthe benefit is you'll get 10-100x faster load times\n",
            "\tsee https://github.com/ggerganov/llama.cpp/issues/91\n",
            "\tuse convert-pth-to-ggml.py to regenerate from original pth\n",
            "\tuse migrate-ggml-2023-03-30-pr613.py if you deleted originals\n",
            "llama_init_from_file: failed to load model\n",
            "llama.cpp: loading model from ./gpt4all-lora-quantized-OSX-m1.bin\n",
            "error loading model: unknown (magic, version) combination: 6d74683c, 0a0d3e6c; is this really a GGML file?\n",
            "AVX = 0 | AVX2 = 0 | AVX512 = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | VSX = 0 | \n",
            "llama_init_from_file: failed to load model\n"
          ]
        }
      ],
      "source": [
        "# old test with OpenAI embeddings\n",
        "# embeddings_model = OpenAIEmbeddings()\n",
        "# ----------------------------------------------------------------\n",
        "\n",
        "# Define your embedding model:\n",
        "# use your own llama model location\n",
        "# i did use dalai to get my .bin\n",
        "# https://cocktailpeanut.github.io/dalai/#/?id=mac\n",
        "# like this: \n",
        "# npx dalai llama install 7B\n",
        "\n",
        "# trying gpt4all\n",
        "import requests\n",
        "\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "local_path = './gpt4all-lora-quantized-OSX-m1.bin'  # replace with your desired local file path\n",
        "Path(local_path).parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Example model. Check https://github.com/nomic-ai/pyllamacpp for the latest models.\n",
        "url = 'https://the-eye.eu/public/AI/models/nomic-ai/gpt4all/gpt4all-lora-quantized-OSX-m1.bin'\n",
        "\n",
        "# send a GET request to the URL to download the file. Stream since it's large\n",
        "response = requests.get(url, stream=True)\n",
        "\n",
        "# open the file in binary mode and write the contents of the response to it in chunks\n",
        "# This is a large file, so be prepared to wait.\n",
        "with open(local_path, 'wb') as f:\n",
        "    for chunk in tqdm(response.iter_content(chunk_size=8192)):\n",
        "        if chunk:\n",
        "            f.write(chunk)\n",
        "# --\n",
        "\n",
        "# Callbacks support token-wise streaming\n",
        "callback_manager = CallbackManager([StreamingStdOutCallbackHandler()])\n",
        "# Verbose is required to pass to the callback manager\n",
        "llm = GPT4All(model=local_path, callback_manager=callback_manager, verbose=True)\n",
        "embeddings_model = LlamaCppEmbeddings(model_path=local_path)\n",
        "# llm = LlamaCpp(model_path=\"../dalai/alpaca/models/7B/ggml-model-q4_0.bin\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f3b72bf",
      "metadata": {
        "id": "0f3b72bf"
      },
      "source": [
        "## Define the Chains\n",
        "\n",
        "BabyAGI relies on three LLM chains:\n",
        "- Task creation chain to select new tasks to add to the list\n",
        "- Task prioritization chain to re-prioritize tasks\n",
        "- Execution Chain to execute the tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "bf4bd5cd",
      "metadata": {
        "id": "bf4bd5cd"
      },
      "outputs": [],
      "source": [
        "class TaskCreationChain(LLMChain):\n",
        "    \"\"\"Chain to generates tasks.\"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n",
        "        \"\"\"Get the response parser.\"\"\"\n",
        "        task_creation_template = (\n",
        "            \"You are an task creation AI that uses the result of an execution agent\"\n",
        "            \" to create new tasks with the following objective: {objective},\"\n",
        "            \" The last completed task has the result: {result}.\"\n",
        "            \" This result was based on this task description: {task_description}.\"\n",
        "            \" These are incomplete tasks: {incomplete_tasks}.\"\n",
        "            \" Based on the result, create new tasks to be completed\"\n",
        "            \" by the AI system that do not overlap with incomplete tasks.\"\n",
        "            \" Return the tasks as an array.\"\n",
        "        )\n",
        "        prompt = PromptTemplate(\n",
        "            template=task_creation_template,\n",
        "            input_variables=[\"result\", \"task_description\", \"incomplete_tasks\", \"objective\"],\n",
        "        )\n",
        "        return cls(prompt=prompt, llm=llm, verbose=verbose)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "b6488ffe",
      "metadata": {
        "id": "b6488ffe"
      },
      "outputs": [],
      "source": [
        "class TaskPrioritizationChain(LLMChain):\n",
        "    \"\"\"Chain to prioritize tasks.\"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n",
        "        \"\"\"Get the response parser.\"\"\"\n",
        "        task_prioritization_template = (\n",
        "            \"You are an task prioritization AI tasked with cleaning the formatting of and reprioritizing\"\n",
        "            \" the following tasks: {task_names}.\"\n",
        "            \" Consider the ultimate objective of your team: {objective}.\"\n",
        "            \" Do not remove any tasks. Return the result as a numbered list, like:\"\n",
        "            \" #. First task\"\n",
        "            \" #. Second task\"\n",
        "            \" Start the task list with number {next_task_id}.\"\n",
        "        )\n",
        "        prompt = PromptTemplate(\n",
        "            template=task_prioritization_template,\n",
        "            input_variables=[\"task_names\", \"next_task_id\", \"objective\"],\n",
        "        )\n",
        "        return cls(prompt=prompt, llm=llm, verbose=verbose)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "b43cd580",
      "metadata": {
        "id": "b43cd580"
      },
      "outputs": [],
      "source": [
        "class ExecutionChain(LLMChain):\n",
        "    \"\"\"Chain to execute tasks.\"\"\"\n",
        "\n",
        "    @classmethod\n",
        "    def from_llm(cls, llm: BaseLLM, verbose: bool = True) -> LLMChain:\n",
        "        \"\"\"Get the response parser.\"\"\"\n",
        "        execution_template = (\n",
        "            \"You are an AI who performs one task based on the following objective: {objective}.\"\n",
        "            \" Take into account these previously completed tasks: {context}.\"\n",
        "            \" Your task: {task}.\"\n",
        "            \" Response:\"\n",
        "        )\n",
        "        prompt = PromptTemplate(\n",
        "            template=execution_template,\n",
        "            input_variables=[\"objective\", \"context\", \"task\"],\n",
        "        )\n",
        "        return cls(prompt=prompt, llm=llm, verbose=verbose)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "0ada0636",
      "metadata": {
        "id": "0ada0636"
      },
      "outputs": [],
      "source": [
        "def get_next_task(task_creation_chain: LLMChain, result: Dict, task_description: str, task_list: List[str], objective: str) -> List[Dict]:\n",
        "    \"\"\"Get the next task.\"\"\"\n",
        "    incomplete_tasks = \", \".join(task_list)\n",
        "    response = task_creation_chain.run(result=result, task_description=task_description, incomplete_tasks=incomplete_tasks, objective=objective)\n",
        "    new_tasks = response.split('\\n')\n",
        "    return [{\"task_name\": task_name} for task_name in new_tasks if task_name.strip()]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3ad996c5",
      "metadata": {
        "id": "3ad996c5"
      },
      "source": [
        "### Define the BabyAGI Controller\n",
        "\n",
        "BabyAGI composes the chains defined above in a (potentially-)infinite loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "d35250ad",
      "metadata": {
        "id": "d35250ad"
      },
      "outputs": [],
      "source": [
        "def prioritize_tasks(task_prioritization_chain: LLMChain, this_task_id: int, task_list: List[Dict], objective: str) -> List[Dict]:\n",
        "    \"\"\"Prioritize tasks.\"\"\"\n",
        "    task_names = [t[\"task_name\"] for t in task_list]\n",
        "    next_task_id = int(this_task_id) + 1\n",
        "    response = task_prioritization_chain.run(task_names=task_names, next_task_id=next_task_id, objective=objective)\n",
        "    new_tasks = response.split('\\n')\n",
        "    prioritized_task_list = []\n",
        "    for task_string in new_tasks:\n",
        "        if not task_string.strip():\n",
        "            continue\n",
        "        task_parts = task_string.strip().split(\".\", 1)\n",
        "        if len(task_parts) == 2:\n",
        "            task_id = task_parts[0].strip()\n",
        "            task_name = task_parts[1].strip()\n",
        "            prioritized_task_list.append({\"task_id\": task_id, \"task_name\": task_name})\n",
        "    return prioritized_task_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e3f1840c",
      "metadata": {
        "id": "e3f1840c"
      },
      "outputs": [],
      "source": [
        "def _get_top_tasks(vectorstore: Chroma, query: str, k: int) -> List[str]:\n",
        "    \"\"\"Get the top k tasks based on the query.\"\"\"\n",
        "\n",
        "    results = vectorstore.similarity_search_with_score(query, k=k)\n",
        "    if not results:\n",
        "        return []\n",
        "    sorted_results, _ = zip(*sorted(results, key=lambda x: x[1], reverse=True))\n",
        "    return [str(item.metadata['task']) for item in sorted_results]\n",
        "\n",
        "def execute_task(vectorstore: Chroma, execution_chain: LLMChain, objective: str, task: str, k: int = 5) -> str:\n",
        "    \"\"\"Execute a task.\"\"\"\n",
        "    context = _get_top_tasks(vectorstore, query=objective, k=k)\n",
        "    return execution_chain.run(objective=objective, context=context, task=task)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1e978938",
      "metadata": {
        "id": "1e978938"
      },
      "outputs": [],
      "source": [
        "\n",
        "class BabyAGI(Chain, BaseModel):\n",
        "    \"\"\"Controller model for the BabyAGI agent.\"\"\"\n",
        "\n",
        "    task_list: deque = Field(default_factory=deque)\n",
        "\n",
        "    task_creation_chain: TaskCreationChain = Field(...)\n",
        "\n",
        "    task_prioritization_chain: TaskPrioritizationChain = Field(...)\n",
        "    \n",
        "    execution_chain: ExecutionChain = Field(...)\n",
        "\n",
        "    task_id_counter: int = Field(1)\n",
        "\n",
        "    vectorstore: VectorStore = Field(init=False)\n",
        "    max_iterations: Optional[int] = None\n",
        "        \n",
        "    class Config:\n",
        "        \"\"\"Configuration for this pydantic object.\"\"\"\n",
        "        arbitrary_types_allowed = True\n",
        "\n",
        "    def add_task(self, task: Dict):\n",
        "        self.task_list.append(task)\n",
        "\n",
        "    def print_task_list(self):\n",
        "        print(\"\\033[95m\\033[1m\" + \"\\n*****TASK LIST*****\\n\" + \"\\033[0m\\033[0m\")\n",
        "        for t in self.task_list:\n",
        "            print(str(t[\"task_id\"]) + \": \" + t[\"task_name\"])\n",
        "\n",
        "    def print_next_task(self, task: Dict):\n",
        "        print(\"\\033[92m\\033[1m\" + \"\\n*****NEXT TASK*****\\n\" + \"\\033[0m\\033[0m\")\n",
        "        print(str(task[\"task_id\"]) + \": \" + task[\"task_name\"])\n",
        "\n",
        "    def print_task_result(self, result: str):\n",
        "        print(\"\\033[93m\\033[1m\" + \"\\n*****TASK RESULT*****\\n\" + \"\\033[0m\\033[0m\")\n",
        "        print(result)\n",
        "        \n",
        "    @property\n",
        "    def input_keys(self) -> List[str]:\n",
        "        return [\"objective\"]\n",
        "    \n",
        "    @property\n",
        "    def output_keys(self) -> List[str]:\n",
        "        return []\n",
        "\n",
        "    def _call(self, inputs: Dict[str, Any]) -> Dict[str, Any]:\n",
        "        \"\"\"Run the agent.\"\"\"\n",
        "        objective = inputs['objective']\n",
        "        first_task = inputs.get(\"first_task\", \"Make a todo list\")\n",
        "        self.add_task({\"task_id\": 1, \"task_name\": first_task})\n",
        "        num_iters = 0\n",
        "        while True:\n",
        "            if self.task_list:\n",
        "                self.print_task_list()\n",
        "\n",
        "                # Step 1: Pull the first task\n",
        "                task = self.task_list.popleft()\n",
        "                self.print_next_task(task)\n",
        "\n",
        "                # Step 2: Execute the task\n",
        "                result = execute_task(\n",
        "                    self.vectorstore, self.execution_chain, objective, task[\"task_name\"]\n",
        "                )\n",
        "                this_task_id = int(task[\"task_id\"])\n",
        "                self.print_task_result(result)\n",
        "\n",
        "                # Step 3: Store the result in Pinecone\n",
        "                result_id = f\"result_{task['task_id']}\"\n",
        "                self.vectorstore.add_texts(\n",
        "                    texts=[result],\n",
        "                    metadatas=[{\"task\": task[\"task_name\"]}],\n",
        "                    ids=[result_id],\n",
        "                )\n",
        "\n",
        "                # Step 4: Create new tasks and reprioritize task list\n",
        "                new_tasks = get_next_task(\n",
        "                    self.task_creation_chain, result, task[\"task_name\"], [t[\"task_name\"] for t in self.task_list], objective\n",
        "                )\n",
        "                for new_task in new_tasks:\n",
        "                    self.task_id_counter += 1\n",
        "                    new_task.update({\"task_id\": self.task_id_counter})\n",
        "                    self.add_task(new_task)\n",
        "                self.task_list = deque(\n",
        "                    prioritize_tasks(\n",
        "                        self.task_prioritization_chain, this_task_id, list(self.task_list), objective\n",
        "                    )\n",
        "                )\n",
        "            num_iters += 1\n",
        "            if self.max_iterations is not None and num_iters == self.max_iterations:\n",
        "                print(\"\\033[91m\\033[1m\" + \"\\n*****TASK ENDING*****\\n\" + \"\\033[0m\\033[0m\")\n",
        "                break\n",
        "        return {}\n",
        "\n",
        "    @classmethod\n",
        "    def from_llm(\n",
        "        cls,\n",
        "        llm: BaseLLM,\n",
        "        vectorstore,\n",
        "        verbose: bool = False,\n",
        "        **kwargs\n",
        "    ) -> \"BabyAGI\":\n",
        "        \"\"\"Initialize the BabyAGI Controller.\"\"\"\n",
        "        task_creation_chain = TaskCreationChain.from_llm(\n",
        "            llm, verbose=verbose\n",
        "        )\n",
        "        task_prioritization_chain = TaskPrioritizationChain.from_llm(\n",
        "            llm, verbose=verbose\n",
        "        )\n",
        "        execution_chain = ExecutionChain.from_llm(llm, verbose=verbose)\n",
        "        return cls(\n",
        "            task_creation_chain=task_creation_chain,\n",
        "            task_prioritization_chain=task_prioritization_chain,\n",
        "            execution_chain=execution_chain,\n",
        "            vectorstore=vectorstore,\n",
        "            **kwargs\n",
        "        )"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "05ba762e",
      "metadata": {
        "id": "05ba762e"
      },
      "source": [
        "## Connect to the Vector Store"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "3d69899b",
      "metadata": {
        "id": "3d69899b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2023-04-14 16:20:40,852] {posthog.py:15} INFO - Anonymized telemetry enabled. See https://docs.trychroma.com/telemetry for more information.\n",
            "[2023-04-14 16:20:40,853] {__init__.py:80} INFO - Running Chroma using direct local API.\n",
            "[2023-04-14 16:20:40,853] {__init__.py:41} WARNING - Using embedded DuckDB with persistence: data will be stored in: chromadb\n",
            "[2023-04-14 16:20:40,860] {duckdb.py:430} INFO - loaded in 0 embeddings\n",
            "[2023-04-14 16:20:40,862] {duckdb.py:440} INFO - loaded in 1 collections\n",
            "[2023-04-14 16:20:40,862] {duckdb.py:85} INFO - collection with name bb-table already exists, returning existing collection\n",
            "[2023-04-14 16:20:40,863] {duckdb.py:388} INFO - Persisting DB to disk, putting it in the save folder: chromadb\n"
          ]
        },
        {
          "ename": "ValidationError",
          "evalue": "1 validation error for BabyAGI\nvectorstore\n  instance of UndefinedType expected (type=type_error.arbitrary_type; expected_arbitrary_type=UndefinedType)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValidationError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[13], line 16\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m# If None, will keep on going forever\u001b[39;00m\n\u001b[1;32m     15\u001b[0m max_iterations: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m---> 16\u001b[0m baby_agi \u001b[39m=\u001b[39m BabyAGI\u001b[39m.\u001b[39;49mfrom_llm(\n\u001b[1;32m     17\u001b[0m     llm\u001b[39m=\u001b[39;49mllm,\n\u001b[1;32m     18\u001b[0m     vectorstore\u001b[39m=\u001b[39;49mvectorstore,\n\u001b[1;32m     19\u001b[0m     verbose\u001b[39m=\u001b[39;49mverbose,\n\u001b[1;32m     20\u001b[0m     max_iterations\u001b[39m=\u001b[39;49mmax_iterations\n\u001b[1;32m     21\u001b[0m )\n",
            "Cell \u001b[0;32mIn[11], line 104\u001b[0m, in \u001b[0;36mBabyAGI.from_llm\u001b[0;34m(cls, llm, vectorstore, verbose, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m task_prioritization_chain \u001b[39m=\u001b[39m TaskPrioritizationChain\u001b[39m.\u001b[39mfrom_llm(\n\u001b[1;32m    101\u001b[0m     llm, verbose\u001b[39m=\u001b[39mverbose\n\u001b[1;32m    102\u001b[0m )\n\u001b[1;32m    103\u001b[0m execution_chain \u001b[39m=\u001b[39m ExecutionChain\u001b[39m.\u001b[39mfrom_llm(llm, verbose\u001b[39m=\u001b[39mverbose)\n\u001b[0;32m--> 104\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m(\n\u001b[1;32m    105\u001b[0m     task_creation_chain\u001b[39m=\u001b[39;49mtask_creation_chain,\n\u001b[1;32m    106\u001b[0m     task_prioritization_chain\u001b[39m=\u001b[39;49mtask_prioritization_chain,\n\u001b[1;32m    107\u001b[0m     execution_chain\u001b[39m=\u001b[39;49mexecution_chain,\n\u001b[1;32m    108\u001b[0m     vectorstore\u001b[39m=\u001b[39;49mvectorstore,\n\u001b[1;32m    109\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs\n\u001b[1;32m    110\u001b[0m )\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/lib/python3.10/site-packages/pydantic/main.py:341\u001b[0m, in \u001b[0;36mpydantic.main.BaseModel.__init__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mValidationError\u001b[0m: 1 validation error for BabyAGI\nvectorstore\n  instance of UndefinedType expected (type=type_error.arbitrary_type; expected_arbitrary_type=UndefinedType)"
          ]
        }
      ],
      "source": [
        "\n",
        "# Initialize the vectorstore as empty\n",
        "# import faiss\n",
        "# embedding_size = 1536\n",
        "# index = faiss.IndexFlatL2(embedding_size)\n",
        "# vectorstore = FAISS(embeddings_model.embed_query, index, InMemoryDocstore({}), {})\n",
        "vectorstore = Chroma(table_name, embeddings_model, 'chromadb')\n",
        "\n",
        "# Ensuring the vectorstore is persisting to the chromadb:\n",
        "vectorstore.persist()\n",
        "\n",
        "# llm = OpenAI(temperature=0)\n",
        "# Logging of LLMChains\n",
        "verbose=False\n",
        "# If None, will keep on going forever\n",
        "max_iterations: Optional[int] = 10\n",
        "baby_agi = BabyAGI.from_llm(\n",
        "    llm=llm,\n",
        "    vectorstore=vectorstore,\n",
        "    verbose=verbose,\n",
        "    max_iterations=max_iterations\n",
        ")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c019a3c0",
      "metadata": {},
      "source": [
        "### Run the BabyAGI\n",
        "\n",
        "Now it's time to create the BabyAGI controller and watch it try to accomplish your objective."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f7957b51",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 570
        },
        "id": "f7957b51",
        "outputId": "c784b996-8a79-495c-a933-8dbe370ab630",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "baby_agi({\"objective\":  \"say hello world\"})"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
